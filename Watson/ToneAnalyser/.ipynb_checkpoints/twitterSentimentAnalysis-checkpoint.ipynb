{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import tweepy\n",
    "import pprint\n",
    "from tweepy import OAuthHandler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TwitterClient(object):\n",
    "    '''\n",
    "    Generic Twitter Class for sentiment analysis.\n",
    "    '''\n",
    "    def __init__(self, consumer_key, consumer_secret, access_token, access_token_secret, ibmUserName, ibmPassword, ibmUrl):\n",
    "        '''\n",
    "        Class constructor or initialization method.\n",
    "        '''\n",
    "        # attempt authentication\n",
    "        try:\n",
    "            # create OAuthHandler object\n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "            # set access token and secret\n",
    "            self.auth.set_access_token(access_token, access_token_secret)\n",
    "            # create tweepy API object to fetch tweets\n",
    "            self.api = tweepy.API(self.auth)\n",
    "            self.ibmUserName = ibmUserName\n",
    "            self.ibmPassword = ibmPassword\n",
    "            self.ibmUrl = ibmUrl\n",
    "        except:\n",
    "            print(\"Error: Authentication Failed\")\n",
    " \n",
    "    def clean_tweet(self, tweet):\n",
    "        '''\n",
    "        Utility function to clean tweet text by removing links, special characters\n",
    "        using simple regex statements.\n",
    "        '''\n",
    "        return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    " \n",
    "    def get_tweet_sentiment(self, tweet):\n",
    "        '''\n",
    "        Utility function to classify sentiment of passed tweet\n",
    "        using textblob's sentiment method\n",
    "        '''\n",
    "        route = '/v3/tone'\n",
    "        fullURL = self.ibmUrl + route\n",
    "        headers = {\n",
    "            \"Content-Type\" : \"application/json\",\n",
    "        }\n",
    "        auth = (self.ibmUserName, self.ibmPassword)\n",
    "        params = {\n",
    "            \"version\" : \"2017-09-21\",\n",
    "            'text' : self.clean_tweet(tweet)\n",
    "        }\n",
    "        analysis = requests.get(params=params, headers=headers, url=fullURL, auth=auth)\n",
    "        print(\"Status Code: {0}; Reason: {1}\".format(analysis.status_code, analysis.reason))\n",
    "        return(analysis.json())\n",
    " \n",
    "    def get_tweets(self, query, count = 10):\n",
    "        '''\n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets\n",
    "        tweets = []\n",
    " \n",
    "        try:\n",
    "            # call twitter api to fetch tweets\n",
    "            fetched_tweets = self.api.search(q = query, count = count)\n",
    "            # parsing tweets one by one\n",
    "            for tweet in fetched_tweets:\n",
    "                # empty dictionary to store required params of a tweet\n",
    "                parsed_tweet = {}\n",
    " \n",
    "                # saving text of tweet\n",
    "                parsed_tweet['text'] = tweet.text\n",
    "                # saving sentiment of tweet\n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
    "                # appending parsed tweet to tweets list\n",
    "                if tweet.retweet_count > 0:\n",
    "                    # if tweet has retweets, ensure that it is appended only once\n",
    "                    if parsed_tweet not in tweets:\n",
    "                        tweets.append(parsed_tweet)\n",
    "                else:\n",
    "                    tweets.append(parsed_tweet)\n",
    " \n",
    "            # return parsed tweets\n",
    "            return tweets\n",
    " \n",
    "        except tweepy.TweepError as e:\n",
    "            # print error (if any)\n",
    "            print(\"Error : \" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"5MczI0tIMBkptp5zixH634WWC\", \"umzlii8NZkHEjabWc9zlH2PC0xkX78aJmNObtYB8X2g2iPf2vD\", \"30615971-WTEPTCJxW5SjDt5hH8Ic7V4khTju3AK3cNtZWs6te\", \"Y6kp67vpBjvIB16aj5xK73fkjprmvO4CMo9W6Mh5KEivL\", \"4e780f54-a944-406b-a551-80e83e795083\", \"dbxFMoZLEvRJ\", \"https://gateway.watsonplatform.net/tone-analyzer/api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCreds():\n",
    "    creds = {}\n",
    "    creds[\"consumerKey\"] = input(\"Enter consumer key: \\n\")\n",
    "    creds[\"consumerSecret\"] = input(\"Enter consumer secret: \\n\")\n",
    "    creds[\"accessToken\"] = input(\"Enter access token: \\n\")\n",
    "    creds[\"tokenSecret\"] = input(\"Enter access token secret: \\n\")\n",
    "    creds[\"ibmUsername\"] = input(\"Enter IBM username: \\n\")\n",
    "    creds[\"ibmPassword\"] = input(\"Enter IBM password: \\n\")\n",
    "    creds[\"ibmURL\"] = input(\"Enter IBM URL: \\n\")\n",
    "    return(creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTweets(creds):\n",
    "    api = TwitterClient(creds['consumerKey'], creds['consumerSecret'], creds['accessToken'], creds['tokenSecret'], creds['ibmUsername'], creds['ibmPassword'], creds['ibmURL'])\n",
    "    targetEntity = input(\"Enter the query to search tweets: \\n\")\n",
    "    count = input(\"Enter the number of tweets to analyse: \\n\")\n",
    "    tweets = api.get_tweets(query = targetEntity, count = count)\n",
    "    iterationCount = 0\n",
    "    for tweet in tweets:\n",
    "        iterationCount = iterationCount + 1\n",
    "        if(iterationCount>10):\n",
    "            print(\"Too many tweets, please wait while final output is generated...\")\n",
    "            break\n",
    "        print(\"Tweet: {0}\".format(tweet['text']))\n",
    "        if(len(tweet['sentiment']['document_tone']['tones']) == 0):\n",
    "            print(\"Sentiment: No sentiment recognized! \\n\\n\")\n",
    "        for tone in tweet['sentiment']['document_tone']['tones']:\n",
    "            print(\"Sentiment: {0}; Score: {1} \\n\\n\".format(tone['tone_name'], tone['score']))\n",
    "    return(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = getTweets(getCreds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentiment': {'document_tone': {'tones': [{'score': 0.590912,\n",
       "     'tone_id': 'sadness',\n",
       "     'tone_name': 'Sadness'}]}},\n",
       " 'text': 'RT @FootyHumour: Jose Mourinho spotted hiding in India after the Bristol City defeat ðŸ˜‚ https://t.co/Mc0tMjvMFk'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tones = []\n",
    "for tweet in tweets:\n",
    "    tones.append(tweet['sentiment']['document_tone']['tones'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toneNames = set({})\n",
    "aggregateSentiments = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tone in tones:\n",
    "    for item in tone:\n",
    "        toneNames.add(item['tone_name'])\n",
    "for tone in tones:\n",
    "    for item in tone:\n",
    "        if(item['tone_name'] not in aggregateSentiments.keys()):\n",
    "            aggregateSentiments.setdefault(item['tone_name'],[]).append(item['score'])\n",
    "        else:\n",
    "            aggregateSentiments[item['tone_name']].append(item['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in aggregateSentiments.keys():\n",
    "    aggregateSentiments[key] = np.mean(np.array(aggregateSentiments[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Analytical': 0.67020400000000002,\n",
       " 'Confident': 0.6408273333333333,\n",
       " 'Joy': 0.63364600000000004,\n",
       " 'Sadness': 0.56707785714285719,\n",
       " 'Tentative': 0.82223100000000005}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregateSentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyseTweets(tweets):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
